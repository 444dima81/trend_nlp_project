import os
from dotenv import load_dotenv
import pandas as pd
from sqlalchemy import create_engine, text
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
from scipy.special import softmax

# -------------------- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ --------------------
load_dotenv()
PG_CONN = os.getenv("PG_CONN")
BATCH_SIZE = 256  # —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π

# -------------------- –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î --------------------
engine = create_engine(PG_CONN)

# -------------------- –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫, –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç --------------------
with engine.begin() as conn:
    conn.execute(text("""
        ALTER TABLE final_db
        ADD COLUMN IF NOT EXISTS sentiment TEXT;
    """))
    conn.execute(text("""
        ALTER TABLE final_db
        ADD COLUMN IF NOT EXISTS confidence FLOAT;
    """))

# -------------------- –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ --------------------
MODEL_NAME = "blanchefort/rubert-base-cased-sentiment"
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)
model.eval()  # –æ—Ç–∫–ª—é—á–∞–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã

labels = ["negative", "neutral", "positive"]

# -------------------- –§—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è --------------------
def get_sentiment_batch(texts):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ (sentiment, confidence) –¥–ª—è –±–∞—Ç—á–∞ —Ç–µ–∫—Å—Ç–æ–≤"""
    inputs = tokenizer(
        texts,
        return_tensors="pt",
        truncation=True,
        padding=True,
        max_length=256
    )
    with torch.no_grad():
        outputs = model(**inputs)
        scores = softmax(outputs.logits.numpy(), axis=1)
        sentiments = [labels[s.argmax()] for s in scores]
        confidences = [float(s.max()) for s in scores]
    return list(zip(sentiments, confidences))

# -------------------- –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª --------------------
def main():
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –ø–æ—Å—Ç—ã –Ω–∞ —Ä—É—Å—Å–∫–æ–º
    query = "SELECT message_id, text_clean FROM final_db WHERE lang='ru'"
    df = pd.read_sql(query, engine)
    total = len(df)
    print(f"–ù–∞–π–¥–µ–Ω–æ {total} —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.")

    if df.empty:
        return

    results = []
    for start in range(0, total, BATCH_SIZE):
        batch_df = df.iloc[start:start+BATCH_SIZE]
        batch_texts = batch_df['text_clean'].tolist()
        batch_result = get_sentiment_batch(batch_texts)
        results.extend(batch_result)
        print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω –±–∞—Ç—á {start}-{start+len(batch_texts)}")

    # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ DataFrame
    df['sentiment'], df['confidence'] = zip(*results)

    # –û–±–Ω–æ–≤–ª—è–µ–º –±–∞–∑—É –ø–æ –∫–∞–∂–¥–æ–º—É message_id
    with engine.begin() as conn:
        for _, row in df.iterrows():
            conn.execute(
                text("""
                    UPDATE final_db
                    SET sentiment = :sentiment,
                        confidence = :confidence
                    WHERE message_id = :mid
                """),
                {"sentiment": row['sentiment'], "confidence": row['confidence'], "mid": int(row['message_id'])}
            )

    # –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á—ë—Ç
    summary = df['sentiment'].value_counts()
    print("\nüìä –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏:")
    print(summary)
    print(f"\n–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(df)} —Å–æ–æ–±—â–µ–Ω–∏–π.")

if __name__ == "__main__":
    main()


# üìä –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏:
# sentiment
# negative    44696
# positive    39013
# neutral      5432
# Name: count, dtype: int64

# –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ 89141 —Å–æ–æ–±—â–µ–Ω–∏–π